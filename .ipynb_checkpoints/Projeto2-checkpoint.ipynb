{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Projeto2_bs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-CJ9T5SO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Projeto2_bs</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Projeto2_bs>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_terms = sc.broadcast(['Mercedes','Fiat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_documents = 0\n",
    "\n",
    "for item in range(0,12):\n",
    "        if item < 10:\n",
    "            file_name = 'part-000{}'.format('0' + str(item))\n",
    "        else:\n",
    "            file_name = 'part-000{}'.format(str(item))\n",
    "\n",
    "        rdd_ = sc.pickleFile(file_name)\n",
    "        count_item = rdd_.count() \n",
    "        \n",
    "        total_documents += count_item\n",
    "        \n",
    "total_texts = sc.broadcast(total_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecta_termos(texto):\n",
    "    termos_ = used_terms.value\n",
    "    exists = [i in texto for i in termos_]\n",
    "    \n",
    "    return (texto, exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_count_txt(item):\n",
    "    texto, unico = item\n",
    "    stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "    stop_words2 = nltk.corpus.stopwords.words('english')\n",
    "    palavras_separadas = texto.lower().strip().split()\n",
    "    return [(palavra, 1) for palavra in palavras_separadas if not palavra in stop_words and palavra not in stop_words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unique_text_elements_0(item):    \n",
    "    if item[1][0] and not item[1][1]:\n",
    "        return item[0]\n",
    "    \n",
    "def filter_unique_text_elements_1(item):    \n",
    "    if item[1][1] and not item[1][0]:\n",
    "        return item[0]\n",
    "    \n",
    "def filter_unique_text_elements_2(item):    \n",
    "    if item[1][1] and item[1][0]:\n",
    "        return item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_idf(item):\n",
    "    palavra, df = item\n",
    "    idf = math.log10(total_texts.value / df)\n",
    "    \n",
    "    return (palavra, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_freq(item):\n",
    "    palavra, df = item\n",
    "    idf = math.log10(1 + df)\n",
    "    \n",
    "    return (palavra, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_df(lista_items):\n",
    "    info = pd.DataFrame(list(lista_items.items()),columns = [\"palavra\",'frequencia']) \n",
    "    info.index = info.palavra\n",
    "    info = info.drop(columns=['palavra'])\n",
    "    \n",
    "    info.sort_values(by=['frequencia'], inplace=True, ascending=False)\n",
    "    return info.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_count_take():\n",
    "    total_documents = 0\n",
    "    \n",
    "    original_rdd_group = sc.pickleFile('part-00000')\n",
    "    \n",
    "    for item in range(1,12):\n",
    "        if item < 10:\n",
    "            file_name = 'part-000{}'.format('0' + str(item))\n",
    "        else:\n",
    "            file_name = 'part-000{}'.format(str(item))\n",
    "\n",
    "        rdd_ = sc.pickleFile(file_name)\n",
    "        \n",
    "        original_rdd_group = original_rdd_group.union(rdd_)\n",
    "    \n",
    "    result = original_rdd_group.map(lambda x: x[1]).map(detecta_termos)\n",
    "\n",
    "    filtered_count_words = result.flatMap(filter_and_count_txt).reduceByKey(lambda x, y : x + y).cache()\n",
    "    filtered_count_words = filtered_count_words.map(df_to_idf)\n",
    "    \n",
    "    take_files_ordered_idf_not_comum = filtered_count_words.takeOrdered(100, key = lambda x: -x[1])\n",
    "    take_files_ordered_idf_comum = filtered_count_words.takeOrdered(100, key = lambda x: x[1])\n",
    "    \n",
    "    return take_files_ordered_idf_not_comum,take_files_ordered_idf_comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_count_take2():\n",
    "    total_documents = 0\n",
    "    \n",
    "    original_rdd_group = sc.pickleFile('part-00000')\n",
    "    \n",
    "    for item in range(1,12):\n",
    "        if item < 10:\n",
    "            file_name = 'part-000{}'.format('0' + str(item))\n",
    "        else:\n",
    "            file_name = 'part-000{}'.format(str(item))\n",
    "\n",
    "        rdd_ = sc.pickleFile(file_name)\n",
    "        \n",
    "        original_rdd_group = original_rdd_group.union(rdd_)\n",
    "    \n",
    "    result = original_rdd_group.map(lambda x: x[1]).map(detecta_termos)\n",
    "\n",
    "    filtered_mercedes = result.filter(filter_unique_text_elements_0)\n",
    "    filtered_mercedes = filtered_mercedes.flatMap(filter_and_count_txt).reduceByKey(lambda x, y : x + y).cache()\n",
    "    filtered_mercedes = filtered_mercedes.map(calculate_freq)\n",
    "    take_files_ordered_idf_mercedes = filtered_mercedes.takeOrdered(100, key = lambda x: -x[1])\n",
    "    \n",
    "    filtered_fiat = result.filter(filter_unique_text_elements_1)\n",
    "    filtered_fiat = filtered_fiat.flatMap(filter_and_count_txt).reduceByKey(lambda x, y : x + y).cache()\n",
    "    filtered_neymar = filtered_fiat.map(calculate_freq)\n",
    "    take_files_ordered_idf_fiat = filtered_fiat.takeOrdered(100, key = lambda x: -x[1])\n",
    "    \n",
    "    filtered_mercedes_fiat = result.filter(filter_unique_text_elements_2)\n",
    "    filtered_mercedes_fiat = filtered_mercedes_fiat.flatMap(filter_and_count_txt).reduceByKey(lambda x, y : x + y).cache()\n",
    "    filtered_mercedes_fiat = filtered_mercedes_fiat.map(calculate_freq)\n",
    "    take_files_ordered_idf_mercedes_fiat = filtered_mercedes_fiat.takeOrdered(100, key = lambda x: -x[1])\n",
    "    \n",
    "    return take_files_ordered_idf_fiat,take_files_ordered_idf_mercedes, take_files_ordered_idf_mercedes_fiat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_idf_not_comum, list_idf_comum = generate_count_take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_idf = gera_df(dict(list_idf_not_comum))\n",
    "df_high_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low_idf = gera_df(dict(list_idf_comum))\n",
    "df_low_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercedes, fiat, mercedes_fiat = generate_count_take2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercedes = gera_df(dict(mercedes))\n",
    "df_fiat = gera_df(dict(fiat))\n",
    "df_mercedes_fiat = gera_df(dict(mercedes_fiat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercedes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fiat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercedes_fiat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud()\n",
    "wordcloud.generate_from_frequencies(frequencies=dict(mercedes))\n",
    "plt.figure(figsize=(40, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud()\n",
    "wordcloud.generate_from_frequencies(frequencies=dict(fiat))\n",
    "plt.figure(figsize=(40, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud()\n",
    "wordcloud.generate_from_frequencies(frequencies=dict(mercedes_fiat))\n",
    "plt.figure(figsize=(40, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
